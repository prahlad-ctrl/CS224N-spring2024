{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TRNSC4MV4AAu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import numpy as np\n",
        "\n",
        "sentences = [\n",
        "    'human feeds dog',\n",
        "    'human walks dog',\n",
        "    'dog follows human',\n",
        "    'dog guards house',\n",
        "    'human lives in house',\n",
        "    'dog lives in house',\n",
        "    'human plays with dog',\n",
        "    'dog fetches ball',\n",
        "    'human throws ball',\n",
        "    'dog sleeps on floor',\n",
        "    'human sleeps on bed',\n",
        "    'dog waits near door',\n",
        "    'human opens door',\n",
        "    'dog runs outside',\n",
        "    'dog returns to human',\n",
        "    'human pats dog',\n",
        "    'dog wags tail',\n",
        "    'human and dog are friends',\n",
        "    'human and dog are pals',\n",
        "    'human trains dog',\n",
        "    'dog learns commands',\n",
        "    'dog eats food',\n",
        "    'human buys food',\n",
        "    'dog stays with human'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "o_pCtEzcLqJf"
      },
      "outputs": [],
      "source": [
        "def get_vocab(data):\n",
        "  i = 1\n",
        "  word2idx = dict()\n",
        "  idx2word = dict()\n",
        "  temp = set()\n",
        "\n",
        "  for sentence in sentences:\n",
        "    for word in sentence.split():\n",
        "      if word not in temp:\n",
        "        temp.add(word)\n",
        "        word2idx[word] = i # mapping word to id\n",
        "        idx2word[i] = word # mapping id to word\n",
        "        i += 1\n",
        "  return i, word2idx, idx2word\n",
        "\n",
        "vocab_size, word2idx, idx2word = get_vocab(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nYgtlQSrNLei"
      },
      "outputs": [],
      "source": [
        "def prev_words(i, doc, window_size):\n",
        "  p_out = []\n",
        "  for index in range(i - window_size, i):\n",
        "    if index >= 0:\n",
        "      p_out.append(word2idx[doc[index]])\n",
        "    else:\n",
        "      p_out.append(0)\n",
        "  return p_out\n",
        "\n",
        "def next_words(i, doc, window_size):\n",
        "  n_out = []\n",
        "  for index in range(i+1, i + window_size + 1):\n",
        "    if index < len(doc):\n",
        "      n_out.append(word2idx[doc[index]])\n",
        "    else:\n",
        "      n_out.append(0)\n",
        "  return n_out\n",
        "\n",
        "def get_training(sentences, window_size = 6):\n",
        "  x = []\n",
        "  y = []\n",
        "  for sentence in sentences:\n",
        "    xi = []\n",
        "    yi = []\n",
        "    sentence = sentence.split()\n",
        "    for index, word in enumerate(sentence):\n",
        "      prev = prev_words(index, sentence, window_size//2)\n",
        "      next = next_words(index, sentence, window_size//2)\n",
        "      assert len(prev) == len(next)\n",
        "      xi.append(prev+next)\n",
        "      yi.append([word2idx[word]])\n",
        "    x.extend(xi)\n",
        "    y.extend(yi)\n",
        "  return x, y\n",
        "\n",
        "window_size = 5\n",
        "x, y = get_training(sentences, window_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNPfDz8PPjhV",
        "outputId": "b6b5fe6c-50bb-41ca-a151-f67098b5dff0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([84, 4]), torch.Size([84]))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_tensor = torch.LongTensor(x)\n",
        "y_tensor = torch.LongTensor(y).squeeze()\n",
        "x_tensor.shape, y_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "R7hMiEpoRcaT"
      },
      "outputs": [],
      "source": [
        "class CBOW(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim):\n",
        "    super(CBOW, self).__init__()\n",
        "    self.embeddinds = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.linear = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "  def forward(self, input):\n",
        "    embeds = self.embeddinds(input)\n",
        "    embed_mean = torch.mean(embeds, dim=1)\n",
        "    out = self.linear(embed_mean)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3pJgyV0SXvw",
        "outputId": "2dd6d197-505e-4369-abb7-89cf65c98b42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 999, loss:  0.8005\n",
            "epoch 1999, loss:  0.4417\n",
            "epoch 2999, loss:  0.3650\n",
            "epoch 3999, loss:  0.3437\n",
            "epoch 4999, loss:  0.3352\n",
            "epoch 5999, loss:  0.3306\n",
            "epoch 6999, loss:  0.3277\n",
            "epoch 7999, loss:  0.3257\n",
            "epoch 8999, loss:  0.3243\n",
            "epoch 9999, loss:  0.3233\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "lr = 0.01\n",
        "epochs = 10000\n",
        "\n",
        "model = CBOW(vocab_size, embedding_dim = 2).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "x_tensor = x_tensor.to(device)\n",
        "y_tensor = y_tensor.to(device)\n",
        "for epoch in range(epochs):\n",
        "  pred = model(x_tensor)\n",
        "  loss = criterion(pred, y_tensor)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if (epoch+1) % 1000 == 0:\n",
        "    print(f'epoch {epoch}, loss: {loss.item(): .4f}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
