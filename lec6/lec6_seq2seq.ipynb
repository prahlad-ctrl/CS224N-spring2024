{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "psFz1r9Rzqc6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, dropout = 0.1):\n",
        "    super(EncoderRNN, self).__init__()\n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size, batch_first= True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    embed = self.dropout(self.embedding(x))\n",
        "    output, hidden = self.gru(embed)\n",
        "\n",
        "    return output, hidden"
      ],
      "metadata": {
        "id": "0uNDbuMrz2yW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self, hidden_size):\n",
        "    super(Attention, self).__init__()\n",
        "    self.w_enc = nn.Linear(hidden_size, hidden_size)\n",
        "    self.w_dec = nn.Linear(hidden_size, hidden_size)\n",
        "    self.V = nn.Linear(hidden_size, 1)\n",
        "\n",
        "  def forward(self, hidden, x):\n",
        "    hidden = hidden.permute(1, 0, 2)\n",
        "    score = torch.tanh(self.w_enc(x) + self.w_dec(hidden))\n",
        "    weights = torch.softmax(self.V(score), dim = 1)\n",
        "    context = torch.bmm(weights.permute(0, 2, 1), x)\n",
        "\n",
        "    return context, weights"
      ],
      "metadata": {
        "id": "w0AILOTA0mV0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout = 0.1):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.attention = Attention(hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size* 2, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input_step, hidden, encoder_outputs):\n",
        "        embed = self.dropout(self.embedding(input_step))\n",
        "        context, _ = self.attention(hidden, encoder_outputs)\n",
        "        rnn_input = torch.cat((embed, context), dim=2)\n",
        "        output, hidden = self.gru(rnn_input, hidden)\n",
        "        prediction = self.out(output.squeeze(1))\n",
        "\n",
        "        return prediction, hidden"
      ],
      "metadata": {
        "id": "hVSi7Kcj2fl6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
        "        batch_size = source.shape[0]\n",
        "        target_len = target.shape[1]\n",
        "        target_vocab_size = self.decoder.out.out_features\n",
        "        outputs = torch.zeros(batch_size, target_len, target_vocab_size).to(self.device)\n",
        "        encoder_outputs, hidden = self.encoder(source)\n",
        "        decoder_input = target[:, 0].unsqueeze(1)\n",
        "\n",
        "        for t in range(1, target_len):\n",
        "            output, hidden = self.decoder(decoder_input, hidden, encoder_outputs)\n",
        "            outputs[:, t, :] = output\n",
        "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1)\n",
        "            decoder_input = target[:, t].unsqueeze(1) if teacher_force else top1.unsqueeze(1)\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "nBO382rM28ee"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 100\n",
        "output_dim = 100\n",
        "hidden_dim = 256\n",
        "batch_size = 32\n",
        "seq_len = 10\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "enc = EncoderRNN(input_dim, hidden_dim).to(device)\n",
        "dec = DecoderRNN(hidden_dim, output_dim).to(device)\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "src = torch.randint(0, input_dim, (batch_size, seq_len)).to(device)\n",
        "trg = torch.randint(0, output_dim, (batch_size, seq_len)).to(device)\n",
        "\n",
        "output = model(src, trg)\n",
        "\n",
        "print(f\"input shape: {src.shape}\")\n",
        "print(f\"output shape: {output.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLbYnSgm3Ht9",
        "outputId": "e36094dc-5202-4606-d529-a9f3bd7f780a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape: torch.Size([32, 10])\n",
            "output shape: torch.Size([32, 10, 100])\n"
          ]
        }
      ]
    }
  ]
}