{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cvPmpt46qGPT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import numpy as np\n",
        "\n",
        "sentences = [\n",
        "    'human feeds dog',\n",
        "    'human walks dog',\n",
        "    'dog follows human',\n",
        "    'dog guards house',\n",
        "    'human lives in house',\n",
        "    'dog lives in house',\n",
        "    'human plays with dog',\n",
        "    'dog fetches ball',\n",
        "    'human throws ball',\n",
        "    'dog sleeps on floor',\n",
        "    'human sleeps on bed',\n",
        "    'dog waits near door',\n",
        "    'human opens door',\n",
        "    'dog runs outside',\n",
        "    'dog returns to human',\n",
        "    'human pats dog',\n",
        "    'dog wags tail',\n",
        "    'human and dog are friends',\n",
        "    'human and dog are pals',\n",
        "    'human trains dog',\n",
        "    'dog learns commands',\n",
        "    'dog eats food',\n",
        "    'human buys food',\n",
        "    'dog stays with human'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vocab(data):\n",
        "  i = 1\n",
        "  word2idx = dict()\n",
        "  idx2word = dict()\n",
        "  temp = set()\n",
        "\n",
        "  for sentence in sentences:\n",
        "    for word in sentence.split():\n",
        "      if word not in temp:\n",
        "        temp.add(word)\n",
        "        word2idx[word] = i # mapping word to id\n",
        "        idx2word[i] = word # mapping id to word\n",
        "        i += 1\n",
        "  return i, word2idx, idx2word\n",
        "\n",
        "vocab_size, word2idx, idx2word = get_vocab(sentences)"
      ],
      "metadata": {
        "id": "jCw-VyEJqPpE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prev_words(i, doc, window_size):\n",
        "  p_out = []\n",
        "  for index in range(i - window_size, i):\n",
        "    if index >= 0:\n",
        "      p_out.append(word2idx[doc[index]])\n",
        "    else:\n",
        "      p_out.append(0)\n",
        "  return p_out\n",
        "\n",
        "def next_words(i, doc, window_size):\n",
        "  n_out = []\n",
        "  for index in range(i+1, i + window_size + 1):\n",
        "    if index < len(doc):\n",
        "      n_out.append(word2idx[doc[index]])\n",
        "    else:\n",
        "      n_out.append(0)\n",
        "  return n_out\n",
        "\n",
        "def get_training(sentences, window_size):\n",
        "  pairs = []\n",
        "  for sentence in sentences:\n",
        "    sentence = sentence.split()\n",
        "    for index, word in enumerate(sentence):\n",
        "      prev = prev_words(index, sentence, window_size//2)\n",
        "      next = next_words(index, sentence, window_size//2)\n",
        "      context_words = prev + next\n",
        "      center_idx = word2idx[word]\n",
        "      for ctx in context_words:\n",
        "        if ctx != 0:\n",
        "          pairs.append([center_idx, ctx])\n",
        "\n",
        "  x, y = zip(*pairs)\n",
        "  return list(x), list(y)\n",
        "\n",
        "window_size = 5\n",
        "x, y = get_training(sentences, window_size)\n",
        ""
      ],
      "metadata": {
        "id": "xER9DTvAqWDK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_tensor = torch.LongTensor(x)\n",
        "y_tensor = torch.LongTensor(y)\n",
        "x_tensor.shape, y_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k9oiAuaryY3",
        "outputId": "c2f621bc-4f0d-44b2-ef1b-6380b17558d3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([192]), torch.Size([192]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SkipGram(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim):\n",
        "    super(SkipGram, self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.linear = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "  def forward(self, input):\n",
        "    embeds = self.embedding(input)\n",
        "    out = self.linear(embeds)\n",
        "    return out"
      ],
      "metadata": {
        "id": "sggGkNFYr9Xe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "lr = 0.01\n",
        "epochs = 10000\n",
        "\n",
        "model = SkipGram(vocab_size, embedding_dim = 2).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "x_tensor = x_tensor.to(device)\n",
        "y_tensor = y_tensor.to(device)\n",
        "for epoch in range(epochs):\n",
        "  pred = model(x_tensor)\n",
        "  loss = criterion(pred, y_tensor)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if (epoch+1) % 1000 == 0:\n",
        "    print(f'epoch {epoch}, loss: {loss.item(): .4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpKmrljHsxy-",
        "outputId": "a1583057-d4e1-49f4-a6bf-20fed2e3b09c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 999, loss:  2.4214\n",
            "epoch 1999, loss:  2.3681\n",
            "epoch 2999, loss:  2.3422\n",
            "epoch 3999, loss:  2.3255\n",
            "epoch 4999, loss:  2.3133\n",
            "epoch 5999, loss:  2.3038\n",
            "epoch 6999, loss:  2.2961\n",
            "epoch 7999, loss:  2.2898\n",
            "epoch 8999, loss:  2.2846\n",
            "epoch 9999, loss:  2.2794\n"
          ]
        }
      ]
    }
  ]
}